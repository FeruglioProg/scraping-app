# ğŸ  Property Finder Argentina - Servidor Dedicado

Sistema completo de scraping de propiedades inmobiliarias en Argentina con arquitectura profesional.

## ğŸš€ InstalaciÃ³n SÃºper RÃ¡pida (1 comando)

\`\`\`bash
curl -fsSL https://raw.githubusercontent.com/tu-repo/property-finder/main/quick-install.sh | bash
\`\`\`

## ğŸ“‹ InstalaciÃ³n Manual

### 1. Preparar el servidor
\`\`\`bash
wget https://raw.githubusercontent.com/tu-repo/property-finder/main/setup-server.sh
chmod +x setup-server.sh
./setup-server.sh
\`\`\`

### 2. Configurar la aplicaciÃ³n
\`\`\`bash
./configure-app.sh
\`\`\`

### 3. Construir y desplegar
\`\`\`bash
./build-and-deploy.sh
\`\`\`

## ğŸ› ï¸ GestiÃ³n de la AplicaciÃ³n

\`\`\`bash
# Ver todos los comandos disponibles
./manage.sh help

# Comandos mÃ¡s comunes
./manage.sh start      # Iniciar servicios
./manage.sh stop       # Detener servicios
./manage.sh logs       # Ver logs en tiempo real
./manage.sh status     # Ver estado de servicios
./manage.sh backup     # Crear backup de BD
./manage.sh monitor    # Abrir dashboard
\`\`\`

## ğŸŒ Acceso a la AplicaciÃ³n

- **AplicaciÃ³n Web**: http://localhost:3000
- **Dashboard Grafana**: http://localhost:3001 (admin/admin123)
- **Prometheus**: http://localhost:9090

## âš™ï¸ ConfiguraciÃ³n

Edita el archivo `.env` para configurar:

\`\`\`bash
# Gmail para notificaciones
GMAIL_USER=tu-email@gmail.com
GMAIL_APP_PASSWORD=tu-app-password

# Proxy Bright Data (opcional)
PROXY_HOST=brd.superproxy.io
PROXY_PORT=33335
PROXY_USERNAME=tu-usuario
PROXY_PASSWORD=tu-password
\`\`\`

## ğŸ—ï¸ Arquitectura

\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Next.js App   â”‚    â”‚  Scraper Worker â”‚    â”‚   PostgreSQL    â”‚
â”‚   (Puerto 3000) â”‚    â”‚   (Background)  â”‚    â”‚   (Puerto 5432) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      Redis      â”‚
                    â”‚   (Puerto 6379) â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

## ğŸ“Š Monitoreo

- **MÃ©tricas en tiempo real** con Prometheus
- **Dashboards visuales** con Grafana
- **Alertas automÃ¡ticas** para problemas
- **Logs centralizados** de todos los servicios

## ğŸ”§ Mantenimiento

### Backup automÃ¡tico
\`\`\`bash
./manage.sh backup
\`\`\`

### Actualizar aplicaciÃ³n
\`\`\`bash
./manage.sh update
\`\`\`

### Ver logs especÃ­ficos
\`\`\`bash
docker-compose logs -f app
docker-compose logs -f worker
\`\`\`

### Escalar workers
\`\`\`bash
docker-compose up -d --scale worker=3
\`\`\`

## ğŸš¨ SoluciÃ³n de Problemas

### Servicios no inician
\`\`\`bash
./manage.sh status
docker-compose logs
\`\`\`

### Problemas de memoria
\`\`\`bash
# Aumentar memoria para Docker
# En Docker Desktop: Settings > Resources > Memory > 4GB+
\`\`\`

### Limpiar sistema
\`\`\`bash
./manage.sh clean
\`\`\`

## ğŸ“ˆ Rendimiento

- **Sin timeouts**: Scraping ilimitado en tiempo
- **Procesamiento paralelo**: MÃºltiples workers
- **CachÃ© inteligente**: Resultados rÃ¡pidos
- **Proxies rotativos**: Evita bloqueos
- **Base de datos optimizada**: Consultas rÃ¡pidas

## ğŸ”’ Seguridad

- **Contenedores aislados**
- **Usuarios no-root**
- **Datos encriptados**
- **Backups automÃ¡ticos**
- **Monitoreo de seguridad**

## ğŸ“ Soporte

Si tienes problemas:

1. Revisa los logs: `./manage.sh logs`
2. Verifica el estado: `./manage.sh status`
3. Reinicia servicios: `./manage.sh restart`
4. Limpia y reinstala: `./manage.sh clean && ./build-and-deploy.sh`

---

ğŸ‰ **Â¡Disfruta de tu sistema de scraping profesional!**
